{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciccioshake/colab/blob/main/testo_segmentato_ottimizzato_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chardet\n",
        "import re\n",
        "import chardet\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Scarica il tokenizer di NLTK se necessario\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Impostazioni per la segmentazione migliorata\n",
        "MAX_LEN = 384  # Lunghezza massima di un segmento\n",
        "OVERLAP = 100  # Sovrapposizione tra segmenti\n",
        "PUNCTUATION = [\".\", \"!\", \"?\", \";\", \":\", \",\"]  # Punti di spezzatura preferiti\n",
        "CHUNK_SIZE = 1024 * 1024  # Dimensione del blocco di lettura (1 MB)\n",
        "\n",
        "\n",
        "# Funzione per tokenizzare il testo in parole senza dipendenze esterne\n",
        "def simple_tokenize(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text)\n",
        "\n",
        "\n",
        "# Funzione per trovare il miglior punto di spezzatura\n",
        "def find_best_split(words, max_len):\n",
        "    \"\"\"\n",
        "    Cerca il miglior punto di spezzatura in base alla punteggiatura.\n",
        "    \"\"\"\n",
        "    if len(words) <= max_len:\n",
        "        return len(words)  # Nessuna spezzatura necessaria\n",
        "\n",
        "    best_split = max_len  # Punto di spezzatura predefinito\n",
        "    for i in range(max_len - 10, max_len - 50, -1):  # Cerca un punto vicino alla fine\n",
        "        if words[i] in PUNCTUATION:\n",
        "            best_split = i + 1  # Include la punteggiatura nel segmento\n",
        "            break\n",
        "    return best_split\n",
        "\n",
        "\n",
        "# Percorsi file aggiornati\n",
        "input_file_path = \"/content/testo_input.txt\"\n",
        "output_file_path = \"/content/testo_segmentato_ottimizzato.txt\"\n",
        "\n",
        "\n",
        "# Elaborazione del file in blocchi\n",
        "with open(input_file_path, \"r\", encoding=\"ISO-8859-1\") as f, open(output_file_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    buffer = []  # Buffer per accumulare parole\n",
        "    segment_count = 0\n",
        "\n",
        "    while True:\n",
        "        chunk = f.read(CHUNK_SIZE)\n",
        "        if not chunk:\n",
        "            break  # Fine del file\n",
        "\n",
        "        # Tokenizza il blocco corrente\n",
        "        words = simple_tokenize(chunk)\n",
        "        buffer.extend(words)\n",
        "\n",
        "        # Segmentazione del buffer\n",
        "        while len(buffer) >= MAX_LEN:\n",
        "            end = find_best_split(buffer, MAX_LEN)\n",
        "            segment = buffer[:end]\n",
        "            segment_count += 1\n",
        "            outfile.write(\n",
        "                f\"Segment {segment_count} (Token Count: {len(segment)}):\\n{' '.join(segment)}\\n\\n\"\n",
        "            )\n",
        "            buffer = buffer[end - OVERLAP :]  # Sovrapposizione\n",
        "\n",
        "    # Elabora eventuali parole rimanenti nel buffer\n",
        "    if buffer:\n",
        "        segment_count += 1\n",
        "        outfile.write(\n",
        "            f\"Segment {segment_count} (Token Count: {len(buffer)}):\\n{' '.join(buffer)}\\n\\n\"\n",
        "        )\n",
        "\n",
        "print(f\"Testo elaborato salvato in {output_file_path}\")"
      ],
      "metadata": {
        "id": "SXDg8ytSm2VA",
        "outputId": "0730805f-c4c5-4372-ec7d-d060f4d296a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (5.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testo elaborato salvato in /content/testo_segmentato_ottimizzato.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Un benvenuto a Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}